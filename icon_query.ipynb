{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first block of code is just importing the requirements of the project\n",
    "\n",
    "import sys \n",
    "import os\n",
    "import h5py\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import stats as sstats\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from random import shuffle\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "import collections\n",
    "import random\n",
    "import mahotas \n",
    "from sklearn.preprocessing import normalize\n",
    "from PIL import Image\n",
    "import imutils\n",
    "import logging\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block of code is importing all the various parts of the project from their respective modules\n",
    "from icon_util import *\n",
    "from methods import *\n",
    "from aberrations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "Loading Completed\n"
     ]
    }
   ],
   "source": [
    "image_set_name = \"icon1k\"\n",
    "\n",
    "hdf5_file = h5py.File('LLD-icon.hdf5', 'r')\n",
    "images, _ = (hdf5_file['data'], hdf5_file['labels/resnet/rc_64'])\n",
    "\n",
    "# transpose the images because they're stored in a weird color channel first format, as indicated by shape[0] being 3\n",
    "images = [np.transpose(i) if i.shape[0] == 3 else i for i in images[:1000]]\n",
    "print(len(images))\n",
    "\n",
    "method_classes = [zernike_method, orb_method, neural_method, sift_method, contour_method]\n",
    "#method_classes = [orb_method]\n",
    "\n",
    "# uncomment this if you want to generate the databases\n",
    "#generate_databases(images, method_classes, image_set_name)\n",
    "methods = load_databases(method_classes, image_set_name)\n",
    "print(\"Loading Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk: 1\n",
      "Chunk: 2\n",
      "Chunk: 3\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# main loop \t#####\n",
    "#####################\n",
    "#results, scores = run(methods, images)\n",
    "run_in_chunks(methods, images, aberrations, chunk_size=100, weights=[0.10353353, 0.17799655, 0.05596501, 0.35731078, 0.30519413])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the logs into a single dataframe for processing\n",
    "log_files = glob(\"Logs/*\") # these are the logs that we're loading\n",
    "print(log_files)\n",
    "joined_logs = pd.concat([pd.read_csv(i) for i in log_files])\n",
    "print(joined_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ranking\")\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
    "joined_logs[joined_logs['method']=='zernike_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[0,0])\n",
    "axes[0,0].set_title('Zernike')\n",
    "joined_logs[joined_logs['method']=='sift_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[0,1])\n",
    "axes[0,1].set_title('Sift')\n",
    "joined_logs[joined_logs['method']=='orb_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[1,0])\n",
    "axes[1,0].set_title('Orb')\n",
    "joined_logs[joined_logs['method']=='neural_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[1,1])\n",
    "axes[1,1].set_title('Neural')\n",
    "joined_logs[joined_logs['method']=='contour_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[2,0])\n",
    "axes[2,0].set_title('Contour')\n",
    "joined_logs[joined_logs['method']=='combined_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[2,1])\n",
    "axes[2,1].set_title('Combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Timing\")\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
    "joined_logs[joined_logs['method']=='zernike_method']['time'].hist(bins=20, figsize=(10,10), ax=axes[0,0])\n",
    "axes[0,0].set_title('Zernike')\n",
    "axes[0,0].set(xlim=(0,0.2))\n",
    "joined_logs[joined_logs['method']=='sift_method']['time'].hist(bins=20, figsize=(10,10), ax=axes[0,1])\n",
    "axes[0,1].set_title('Sift')\n",
    "#axes[0,1].set(xlim=(0,0.2))\n",
    "joined_logs[joined_logs['method']=='orb_method']['time'].hist(bins=20, figsize=(10,10), ax=axes[1,0])\n",
    "axes[1,0].set_title('Orb')\n",
    "axes[1,0].set(xlim=(0,0.2))\n",
    "joined_logs[joined_logs['method']=='neural_method']['time'].hist(bins=20, figsize=(10,10), ax=axes[1,1])\n",
    "axes[1,1].set_title('Neural')\n",
    "axes[1,1].set(xlim=(0,0.2))\n",
    "joined_logs[joined_logs['method']=='contour_method']['time'].hist(bins=20, figsize=(10,10), ax=axes[2,0])\n",
    "axes[2,0].set_title('Contour')\n",
    "#axes[2,0].set(xlim=(0,0.2))\n",
    "joined_logs[joined_logs['method']=='combined_method']['time'].hist(bins=20, figsize=(10,10), ax=axes[2,1])\n",
    "axes[2,1].set_title('Combined')\n",
    "axes[2,1].set(xlim=(0,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_logs[joined_logs['method']=='neural_method']['rank'].plot.hist(bins=100)\n",
    "# joined_logs.plot.kde()\n",
    "# pd.plotting.andrews_curves(joined_logs['rank'], 'method')\n",
    "# print(list('ABCD'))\n",
    "\n",
    "#joined_logs.groupby('method').plot.hist()\n",
    "#joined_logs[['method', 'rank']].hist(by='method')\n",
    "#joined_logs[['method','rank','aberration']].groupby('method').plot.hist(bins=100, label='method')\n",
    "#joined_logs.groupby('method').plot(kind='hist', subplots=True, figsize=(6,6))\n",
    "#joined_logs[joined_logs['method']=='zernike_method'].hist(bins=20, figsize=(20,20))\n",
    "#joined_logs[(joined_logs['method']=='zernike_method') & (joined_logs['aberration']=='ab_id')]\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "joined_logs[joined_logs['method']=='combined_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[0])\n",
    "axes[0].set_title('Weighted Combined')\n",
    "joined_logs[joined_logs['method']=='uwcombined_method']['rank'].hist(bins=20, figsize=(10,10), ax=axes[1])\n",
    "axes[1].set_title('Unweighted Combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## plot query image and top 11 hits, just for checking purposes  \n",
    "# plot_results(Data, matched_list_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "\n",
    "# Load all the Training data into a single dataframe for processing\n",
    "log_files = glob(\"Training/*\") # these are the logs that we're loading\n",
    "print(log_files)\n",
    "training_logs = pd.concat([pd.read_csv(i) for i in log_files])\n",
    "print(training_logs)\n",
    "\n",
    "numbers = [i for i in range(len(images))]\n",
    "random.shuffle(numbers)\n",
    "training = numbers[0:int(0.8*len(images))]\n",
    "test = numbers[len(training):]\n",
    "print(str(len(training))+\" training images\")\n",
    "print(str(len(test))+\" test images\")\n",
    "\n",
    "training_set = training_logs[training_logs[\"idx\"].astype(int).isin(training)]\n",
    "training_data = training_set[training_set.columns[:5]].to_numpy()\n",
    "training_labels = training_set[training_set.columns[5]].to_numpy()\n",
    "\n",
    "clf = LogisticRegression(random_state = 0, solver = 'lbfgs', multi_class = 'multinomial').fit(training_data, training_labels)\n",
    "logistic_weights = clf.coef_[0]/sum(clf.coef_[0])\n",
    "print('Logistic Weights')\n",
    "print(logistic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### logsitic regression for weights of 4 methods\n",
    "# numbers = [i for i in range(100,200)]\n",
    "\n",
    "# ### randomly create training and test set\n",
    "# random.shuffle(numbers)\n",
    "# training = numbers[0:60]\n",
    "# testing = numbers[60:100]\n",
    "\n",
    "# ### search for a particular mutation\n",
    "# mutation_string = 'ab_line_circle'\n",
    "# print(mutation_string)\n",
    "\n",
    "# ### set threshold for contour and sift, set accuracy cutoff (top 10 or top 20)\n",
    "# contour_thresh = 0\n",
    "# sift_thresh = 0\n",
    "# rank_cutoff = 20\n",
    "\n",
    "# ### create training set, filter for mutation name and thresholds \n",
    "# input_score_mutation = input_score[(input_score[\"mutation\"].str.find(mutation_string) > -1) & (input_score[\"image\"].astype(float).isin(training)) & ((input_score[\"contour_orig\"].astype(float) >= contour_thresh) & (input_score[\"sift_orig\"].astype(float) >= sift_thresh))]\n",
    "# input_score_mutation = input_score_mutation.values\n",
    "\n",
    "# ### create test data set, not used for training\n",
    "# input_score_test = input_score[(input_score[\"mutation\"].str.find(mutation_string) > -1) & (input_score[\"image\"].astype(float).isin(testing) ) & ((input_score[\"contour_orig\"].astype(float) >= contour_thresh) & (input_score[\"sift_orig\"].astype(float) >= sift_thresh))]\n",
    "# input_score_test = pd.DataFrame(input_score_test,columns = ['contour_score','zernike_score','sift_score','orb_score','image','success','mutation','contour_orig','sift_orig'])\n",
    "\n",
    "# ### run logistic regression on training data\n",
    "# clf = LogisticRegression(random_state = 0, solver = 'lbfgs', multi_class = 'multinomial').fit(input_score_mutation[:,(0,1,2,3)], input_score_mutation[:,5])\n",
    "# logistic_weights = clf.coef_[0]/sum(clf.coef_[0])\n",
    "# print('Logistic Weights')\n",
    "# print(logistic_weights)\n",
    "\n",
    "# ### use weights to calculate weighted score and rank on training set\n",
    "# input_score_mutation = pd.DataFrame(input_score_mutation,columns = ['contour_score','zernike_score','sift_score','orb_score','image','success','mutation','contour_orig','sift_orig'])\n",
    "\n",
    "# input_score_mutation[\"contour_score\"] = input_score_mutation[\"contour_score\"].astype(float)\n",
    "# input_score_mutation[\"zernike_score\"] = input_score_mutation[\"zernike_score\"].astype(float)\n",
    "# input_score_mutation[\"sift_score\"] = input_score_mutation[\"sift_score\"].astype(float)\n",
    "# input_score_mutation[\"orb_score\"] = input_score_mutation[\"orb_score\"].astype(float)\n",
    "\n",
    "# input_score_mutation[\"avg_score\"] = .25*input_score_mutation[\"contour_score\"] + .25*input_score_mutation[\"zernike_score\"] + .25*input_score_mutation[\"sift_score\"] + .25*input_score_mutation[\"orb_score\"]\n",
    "# input_score_mutation[\"weight_score\"] = logistic_weights[0]*input_score_mutation[\"contour_score\"] + logistic_weights[1]*input_score_mutation[\"zernike_score\"] + logistic_weights[2]*input_score_mutation[\"sift_score\"] + logistic_weights[3]*input_score_mutation[\"orb_score\"]\n",
    "# input_score_mutation['Avg_Rank'] = input_score_mutation.groupby(['image','mutation'])['avg_score'].rank(ascending=False)\t\n",
    "# input_score_mutation['Weight_Rank'] = input_score_mutation.groupby(['image','mutation'])['weight_score'].rank(ascending=False)\t\n",
    "\n",
    "# ### use weights to calculate weighted score and rank on test set\n",
    "# input_score_test[\"contour_score\"] = input_score_test[\"contour_score\"].astype(float)\n",
    "# input_score_test[\"zernike_score\"] = input_score_test[\"zernike_score\"].astype(float)\n",
    "# input_score_test[\"sift_score\"] = input_score_test[\"sift_score\"].astype(float)\n",
    "# input_score_test[\"orb_score\"] = input_score_test[\"orb_score\"].astype(float)\n",
    "\n",
    "# input_score_test[\"avg_score\"] = .25*input_score_test[\"contour_score\"] + .25*input_score_test[\"zernike_score\"] + .25*input_score_test[\"sift_score\"] + .25*input_score_test[\"orb_score\"]\n",
    "# input_score_test[\"weight_score\"] = logistic_weights[0]*input_score_test[\"contour_score\"] + logistic_weights[1]*input_score_test[\"zernike_score\"] + logistic_weights[2]*input_score_test[\"sift_score\"] + logistic_weights[3]*input_score_test[\"orb_score\"]\n",
    "# input_score_test['Avg_Rank'] = input_score_test.groupby(['image','mutation'])['avg_score'].rank(ascending=False)\t\n",
    "# input_score_test['Weight_Rank'] = input_score_test.groupby(['image','mutation'])['weight_score'].rank(ascending=False)\t\n",
    "\n",
    "# ### check the rank of the original image, see if image was within the top 10 or top 20 search results\n",
    "# successes = input_score_mutation[input_score_mutation[\"success\"].astype(float) == 1]\n",
    "\n",
    "# avg_rank = sum(successes['Avg_Rank'])/successes.shape[0]\n",
    "# weight_rank = sum(successes['Weight_Rank'])/successes.shape[0]\n",
    "# top10_avg_rank = len( successes[(successes['Avg_Rank'] <= rank_cutoff)] )\n",
    "# top10_weight_rank = len( successes[(successes['Weight_Rank'] <= rank_cutoff)] )\n",
    "\n",
    "# print('Training Accuracy')\n",
    "# print((top10_avg_rank,top10_weight_rank))\n",
    "\n",
    "# successes_t = input_score_test[input_score_test[\"success\"].astype(float) == 1]\n",
    "\n",
    "# avg_rank_t = sum(successes_t['Avg_Rank'])/successes_t.shape[0]\n",
    "# weight_rank_t = sum(successes_t['Weight_Rank'])/successes_t.shape[0]\n",
    "# top10_avg_rank_t = len( successes_t[(successes_t['Avg_Rank'] <= rank_cutoff)] )\n",
    "# top10_weight_rank_t = len( successes_t[(successes_t['Weight_Rank'] <= rank_cutoff)] )\n",
    "\n",
    "# print('Testing Accuracy')\n",
    "# print((top10_avg_rank_t,top10_weight_rank_t))\n",
    "\n",
    "# #input_score.to_csv(path_or_buf='./score_result_2.csv', sep=',',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### display an image\n",
    "# image_index = 50\n",
    "# Data = gray(images[image_index])\n",
    "# Data, mutation = ab_random(Data, n = 9)\n",
    "\n",
    "# imgplot = plt.imshow(Data, cmap=plt.cm.gray)\n",
    "# plt.axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
